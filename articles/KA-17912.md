---
title: "Entendendo o armazenamento em cache de diretórios"
description: "Saiba como o armazenamento em cache do dispatcher acontece no Adobe Experience Manager e como ele pode ser configurado."
solution: Experience Manager
product: Experience Manager
applies-to: "Experience Manager"
keywords: "KCS, entender diretórios de armazenamento em cache, AEM, Adobe Experience Manager, Práticas recomendadas"
resolution: Resolution
internal-notes: null
bug: false
article-created-by: Oleksandra Marchenko
article-created-date: "1/18/2024 3:39:17 PM"
article-published-by: Oleksandra Marchenko
article-published-date: "1/18/2024 3:44:47 PM"
version-number: 9
article-number: KA-17912
dynamics-url: "https://adobe-ent.crm.dynamics.com/main.aspx?forceUCI=1&pagetype=entityrecord&etn=knowledgearticle&id=063c58b9-17b6-ee11-a569-6045bd006a22"
source-git-commit: 56cc56c649cc946c55a99e24ed8f27165db207e3
workflow-type: tm+mt
source-wordcount: '1533'
ht-degree: 0%

---

# Compreensão de diretórios de cache


Este documento explica como ocorre o armazenamento em cache do dispatcher e como ele pode ser configurado.

## Descrição {#description}


<b>Ambiente</b>
Adobe Experience Manager

<b>Problema/Sintomas</b>
Este documento explica como ocorre o armazenamento em cache do dispatcher e como ele pode ser configurado.
[Índice](https://experienceleague.adobe.com/docs/experience-cloud-kcs/kbarticles/KA-17490.html)

## Resolução {#resolution}


<b>Armazenamento de Diretórios em Cache</b>

Usamos os seguintes diretórios de cache padrão em nossas instalações de linha de base

- Autor

   - /mnt/var/www/author
- Editor

   - /mnt/var/www/html


Quando cada solicitação passa pelo dispatcher, as solicitações seguem as regras configuradas para manter uma versão armazenada em cache localmente da resposta dos itens elegíveis.

<b>Observação:</b>

Intencionalmente, mantemos a carga de trabalho publicada separada da carga de trabalho do autor, pois quando o Apache procura um arquivo no DocumentRoot, ele não sabe de qual instância AEM ele veio. Portanto, mesmo que o cache esteja desativado no farm do autor, se DocumentRoot do autor for igual ao publicador, ele fornecerá arquivos do cache quando presentes. Isso significa que você fornecerá arquivos de autor do cache publicado e proporcionará uma experiência de combinação realmente horrível para seus visitantes. Manter diretórios DocumentRoot separados para diferentes conteúdos publicados também é uma péssima ideia. Você terá que criar vários itens em cache novamente, que não diferem entre sites como clientlibs, além de precisar configurar um agente de limpeza de replicação para cada DocumentRoot configurado, aumentando a sobrecarga de limpeza com cada ativação de página. Conte com o namespace de arquivos e seus caminhos completos em cache e evite várias DocumentRoots para sites publicados.



<b>Arquivos de configuração</b>

O Dispatcher controla o que é qualificado como armazenável em cache na seção /cache de qualquer arquivo farm. 
Nos farms de configuração de linha de base do AMS, você encontrará nossas inclusões, como mostrado abaixo:


```
/cache { 
    /rules { 
        $include "/etc/httpd/conf.dispatcher.d/cache/ams_author_cache.any" 
    }
```


Ao criar as regras para o que armazenar em cache ou não, consulte a documentação [aqui](https://experienceleague.adobe.com/docs/experience-manager-dispatcher/using/configuring/dispatcher-configuration.html?lang=en#configuring-the-dispatcher-cache-cache)



<b>Autor em cache</b>

Vimos que há muitas implementações em que as pessoas não armazenam em cache conteúdo do autor. 
Eles estão perdendo um grande avanço no desempenho e na capacidade de resposta a seus autores.

Vamos discutir a estratégia adotada na configuração do farm do autor para armazenar em cache corretamente.

Esta é uma seção base de autor/cache do arquivo farm do autor:


```
/cache { 
    /docroot "/mnt/var/www/author" 
    /statfileslevel "2" 
    /allowAuthorized "1" 
    /rules { 
        $include "/etc/httpd/conf.dispatcher.d/cache/ams_author_cache.any" 
    } 
    /invalidate { 
        /0000 { 
            /glob "*" 
            /type "allow" 
        } 
    } 
    /allowedClients { 
        /0000 { 
            /glob "*.*.*.*" 
            /type "deny" 
        } 
        $include "/etc/httpd/conf.dispatcher.d/cache/ams_author_invalidate_allowed.any" 
    } 
}
```


O importante a ser observado aqui é que o <b>/docroot</b> é definido para o diretório de cache do autor.

<b>Observação:</b>

Verifique se o DocumentRoot no arquivo .vhost do autor corresponde ao parâmetro farms /docroot.

A instrução include das regras de cache inclui o arquivo <b>/etc/httpd/conf.dispatcher.d/cache/ams_author_cache.any</b> que contém estas regras:


```
/0000 { 
 /glob "*" 
 /type "deny" 
} 
/0001 { 
 /glob "/libs/*" 
 /type "allow" 
} 
/0002 { 
 /glob "/libs/*.html" 
 /type "deny" 
} 
/0003 { 
 /glob "/libs/granite/csrf/token.json" 
 /type "deny" 
} 
/0004 { 
 /glob "/apps/*" 
 /type "allow" 
} 
/0005 { 
 /glob "/apps/*.html" 
 /type "deny" 
} 
/0006 { 
 /glob "/libs/cq/core/content/welcome.*" 
 /type "deny" 
}
```


Em um cenário de criação, o conteúdo é alterado o tempo todo e de propósito. Você só deseja armazenar em cache itens que não serão alterados com frequência.
Temos regras para armazenar em cache /libs porque elas fazem parte da instalação básica do AEM e seriam alteradas até que você instalasse um Service Pack, Cumulative Fix Pack, Atualização ou Hotfix. Armazenar esses elementos em cache faz muito sentido e realmente beneficia a experiência de criação dos usuários finais que usam o site.

<b>Observação:</b>

Lembre-se de que essas regras também fazem cache <b>/apps</b> é aqui que reside o código de aplicativo personalizado. Se você estiver desenvolvendo seu código nesta instância, será muito confuso quando você salvar o arquivo e não verá se ele reflete na interface do usuário, pois ele serve uma cópia em cache. A intenção aqui é que, se você fizer uma implantação do seu código no AEM, ela também será infrequente, e parte de suas etapas de implantação deve ser limpar o cache do autor. Novamente, o benefício é enorme, tornando seu código que pode ser armazenado em cache mais rápido para os usuários finais.



<b>ServeOnStale (também conhecido como Serve on Stale / SOS)</b>

Esta é uma dessas joias de um recurso do dispatcher. Se o editor estiver sob carga ou não responder, normalmente emitirá um código de resposta http 502 ou 503. Se isso acontecer e esse recurso estiver ativado, o dispatcher será instruído a ainda veicular o conteúdo que ainda estiver no cache, como um melhor esforço, mesmo que não seja uma cópia atualizada. É melhor servir algo se você tiver recebido, em vez de apenas mostrar uma mensagem de erro que não oferece funcionalidade.

<b>Observação:</b>

Lembre-se de que, se o renderizador do editor tiver um tempo limite de soquete ou uma mensagem de erro 500, esse recurso não será acionado. Se o AEM estiver inacessível, esse recurso não fará nada.

Essa configuração pode ser definida em qualquer farm, mas aplicá-la aos arquivos de farm publicados faz sentido. Este é um exemplo de sintaxe do recurso habilitado em um arquivo farm:


```
/cache { 
    /serveStaleOnError "1"
```




<b>Armazenamento em cache de páginas com parâmetros/argumentos de consulta</b>

<b>Observação:</b>

Um dos comportamentos normais do módulo Dispatcher é que, se uma solicitação tiver um parâmetro de consulta no URI (normalmente mostrado como /content/page.html)<b>?myquery=value</b>) ignorará o armazenamento em cache do arquivo e irá diretamente para a instância do AEM. Essa solicitação é considerada uma página dinâmica e não deve ser armazenada em cache. Isso pode causar um efeito negativo na eficiência do cache.

Se você tiver páginas em AEM que aceitam argumentos de GET/parâmetros de consulta na linha de endereço que ajudam a página a operar, mas não renderizam HTML diferentes, elas são boas candidatas para esse elemento de configuração.

Você pode informar ao dispatcher quais argumentos ignorar e ainda armazenar a página em cache.

Como exemplo, alguém criou um mecanismo de referência de deep link de redes sociais que usa a referência de argumento no URI para saber de onde a pessoa veio.

<b>Exemplo de uso:</b>

[https://www.retail.com/home.html?reference=android](https://www.retail.com/home.html?reference=android)

[https://www.retail.com/home.html?reference=facebook](https://www.retail.com/home.html?reference=facebook)

A página é 100% armazenável em cache, mas não armazena em cache porque os argumentos estão presentes. 
Para contornar isso, adicionamos a seguinte seção ao arquivo de configuração do farm:


```
/cache { 
    /ignoreUrlParams { 
        /0001 { /glob "*" /type "deny" } 
        /0002 { /glob "reference" /type "allow" } 
    }
```


Agora, quando o Dispatcher visualizar a solicitação, ele ignorará o fato de que a solicitação tem o parâmetro de consulta de referência e ainda armazenará a página em cache.



<b>Armazenamento em cache de cabeçalhos de resposta</b>

É bastante óbvio que o dispatcher armazene em cache páginas .html e clientlibs, mas você sabia que também pode armazenar em cache cabeçalhos de resposta específicos junto com o conteúdo em um arquivo com o mesmo nome, mas com extensão .h? Isso permite que a próxima resposta não seja apenas ao conteúdo, mas aos cabeçalhos de resposta que devem acompanhá-lo do cache.

AEM pode lidar com mais do que apenas codificação UTF-8.

Às vezes, os itens têm cabeçalhos especiais que ajudam a controlar os detalhes de codificação do TTL de cache e os carimbos de data e hora da última modificação.

Esses valores, quando armazenados em cache, são removidos por padrão, e o servidor Web Apache httpd fará seu próprio trabalho de processamento do ativo com seus métodos normais de manipulação de arquivos, que normalmente é limitado à adivinhação de tipo mime com base em extensões de arquivo.

Se o dispatcher armazenar o ativo em cache e os cabeçalhos desejados, você poderá expor a experiência adequada e garantir que todos os detalhes o transformem no navegador dos clientes.

Este é um exemplo de um farm com os cabeçalhos para armazenar em cache especificados:


```
/cache { 
 /headers { 
  "Cache-Control" 
  "Content-Disposition" 
  "Content-Type" 
  "Expires" 
  "Last-Modified" 
  "X-Content-Type-Options" 
 } 
}
```


No exemplo, eles configuraram o AEM para servir cabeçalhos que o CDN procura para saber quando invalidar seu cache. Isso significa que agora o AEM pode ditar corretamente quais arquivos são invalidados com base nos cabeçalhos.

<b>Observação:</b>

Lembre-se de que não é possível usar expressões regulares ou correspondência glob. É uma lista literal dos cabeçalhos a serem armazenados em cache. Coloque somente em uma lista dos cabeçalhos literais que deseja armazenar em cache.



<b>Invalidar automaticamente o período de carência</b>

Em sistemas AEM que têm muita atividade de autores que fazem muitas ativações de página, você pode ter uma condição de corrida em que ocorrem invalidações repetidas. Solicitações de liberação muito repetidas são desnecessárias e você pode integrar alguma tolerância para não repetir uma liberação até que o período de carência tenha sido eliminado.

<b>Exemplo de como isso funciona:</b>

Se você tiver cinco solicitações para invalidar /content/exampleco/en/, todas ocorrerão em um período de 3 segundos.

Com esse recurso desativado, você invalidaria o diretório de cache /content/exampleco/en/ 5 vezes.

Com esse recurso ativado e definido como 5 segundos, ele invalidaria o diretório de cache /content/exampleco/en/once.

Este é um exemplo de sintaxe desse recurso sendo configurado para um período de carência de 5 segundos:


```
/cache { 
    /gracePeriod "5"
```




<b>Invalidação baseada em TTL</b>

Um recurso mais recente do módulo do dispatcher foi <b>Tempo de vida (TTL)</b> opções de invalidação com base em para itens em cache. Quando um item é armazenado em cache, ele procura a presença de cabeçalhos de controle de cache e gera um arquivo no diretório de cache com o mesmo nome e um <b>.ttl</b> extensão.

Este é um exemplo do recurso que está sendo configurado no arquivo de configuração do farm:


```
/cache { 
    /enableTTL "1"
```


<b>Observação:</b>

Lembre-se que o AEM ainda precisa ser configurado para enviar cabeçalhos TTL para que o Dispatcher os honre. Alternar esse recurso permite que o Dispatcher saiba apenas quando remover os arquivos para os quais o AEM enviou cabeçalhos de controle de cache. Se o AEM não começar a enviar cabeçalhos TTL, o dispatcher não fará nada de especial aqui.



<b>Regras de Filtro de Cache</b>

Este é um exemplo de uma configuração de linha de base para quais elementos armazenar em cache em um publicador:


```
/cache{ 
    /0000 { 
        /glob "*" 
        /type "allow" 
    } 
    /0001 { 
        /glob "/libs/granite/csrf/token.json" 
        /type "deny" 
    }
```


Queremos tornar nosso site publicado ganancioso quanto possível e armazenar tudo em cache.

Se houver elementos que interrompem a experiência quando armazenados em cache, será possível adicionar regras para remover a opção para armazenar esse item em cache. Como você vê no exemplo acima, os tokens csrf nunca devem ser armazenados em cache e foram excluídos. Mais detalhes sobre a gravação dessas regras podem ser encontrados [aqui](https://experienceleague.adobe.com/docs/experience-manager-dispatcher/using/configuring/dispatcher-configuration.html?lang=en#configuring-the-dispatcher-cache-cache).
